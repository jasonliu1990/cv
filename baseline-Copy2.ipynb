{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Flatten, Dense, Input, \n",
    "                                     Dropout, BatchNormalization,\n",
    "                                     Conv2D, MaxPooling2D, \n",
    "                                     GlobalMaxPooling2D, GlobalAveragePooling2D,)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_show(img, name='image'):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img):\n",
    "    out_w = 128\n",
    "    out_h = 128\n",
    "    top_size = int((128 - img.shape[0]) / 2)\n",
    "    bottom_size = int((128 - img.shape[0]) / 2)\n",
    "    dif_1 = 128 - (top_size + bottom_size + img.shape[0])\n",
    "    top_size += dif_1\n",
    "    left_size = int((128 - img.shape[1]) / 2)\n",
    "    right_size = int((128 - img.shape[1]) / 2)\n",
    "    dif_2 = 128 - (left_size + right_size + img.shape[1])\n",
    "    left_size += dif_2    \n",
    "    if img.shape[1] <= 128:\n",
    "        constant = cv2.copyMakeBorder(img, \n",
    "                                  top_size, bottom_size, left_size, right_size, \n",
    "                                  borderType=cv2.BORDER_CONSTANT, \n",
    "                                  value=(255, 255, 255))\n",
    "    else:\n",
    "        constant = cv2.copyMakeBorder(img, \n",
    "                          top_size, bottom_size, 0, 0, \n",
    "                          borderType=cv2.BORDER_CONSTANT, \n",
    "                          value=(255, 255, 255))\n",
    "        constant = cv2.resize(constant, (128, 128))\n",
    "        \n",
    " \n",
    "    return constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(img):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh1 = cv2.threshold(gray, 110, 255, cv2.THRESH_OTSU)   \n",
    "    gaussian = cv2.GaussianBlur(thresh1, (3, 3), 1)\n",
    "    kernel = np.zeros((3, 3), np.uint8)\n",
    "    erosion_1 = cv2.erode(gaussian, kernel, iterations=1)\n",
    "\n",
    "    img2 = 255 - erosion_1\n",
    "    img2 = cv2.resize(img2, (64, 64))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    fold_list = os.listdir(train_dir)\n",
    "    trainX_list = []\n",
    "    trainY_list = []\n",
    "    testX_list = []\n",
    "    testY_list = []\n",
    "\n",
    "    for f in fold_list:\n",
    "        label = int(f)\n",
    "        img_list = os.listdir(f'{train_dir}{f}')\n",
    "        tmp_datasetX = []\n",
    "        tmp_datasetY = []\n",
    "        for img_p in img_list:\n",
    "            try:\n",
    "                img = cv2.imread(f'{train_dir}{f}/{img_p}')\n",
    "#                 if (img.shape[0] != 128) or (img.shape[1] != 128):\n",
    "#                     img = padding(img)\n",
    "                img = preprocessing_img(img)\n",
    "#                 print(img.shape)\n",
    "                label = int(f)\n",
    "                tmp_datasetX.append(img)\n",
    "                tmp_datasetY.append(label)\n",
    "            except Exception as e:\n",
    "                print(f, img_p)\n",
    "                print(e)\n",
    "        \n",
    "        trainX, testX, trainY, testY = train_test_split(tmp_datasetX, tmp_datasetY, test_size=0.2, random_state=42)\n",
    "        trainX_list.extend(trainX)\n",
    "        trainY_list.extend(trainY)\n",
    "        testX_list.extend(testX)\n",
    "        testY_list.extend(testY)\n",
    "    trainX_ary = np.array(trainX_list)\n",
    "    trainY_ary = np.array(trainY_list)\n",
    "    testX_ary = np.array(testX_list)\n",
    "    testY_ary = np.array(testY_list)\n",
    "    print(f'trainX: {trainX_ary.shape}')\n",
    "    print(f'trainY: {trainY_ary.shape}')\n",
    "    print(f'testX: {testX_ary.shape}')\n",
    "    print(f'testY: {testY_ary.shape}')\n",
    "        \n",
    "    return trainX_ary, testX_ary, trainY_ary, testY_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'./data-clean/'\n",
    "df = pd.read_csv('word_idx_df.csv', converters={'idx':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX: (47930, 64, 64, 3)\n",
      "trainY: (47930,)\n",
      "testX: (12391, 64, 64, 3)\n",
      "testY: (12391,)\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = load_data(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, num_classes=800)\n",
    "testY = keras.utils.to_categorical(testY, num_classes=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47930, 64, 64, 3)\n",
      "(12391, 64, 64, 3)\n",
      "(47930, 800)\n",
      "(12391, 800)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47930, 128, 128, 3)\n",
      "(12391, 128, 128, 3)\n",
      "(47930, 800)\n",
      "(12391, 800)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8463"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX_pre = []\n",
    "# trainY_pre = []\n",
    "# for x, y in zip(trainX, trainY):\n",
    "#     tmp_img = preprocessing_img(x)\n",
    "#     trainX_pre.append(tmp_img)\n",
    "#     trainY_pre.append(y)\n",
    "\n",
    "# testX_pre = []\n",
    "# testY_pre = []\n",
    "# for x, y in zip(testX, testY):\n",
    "#     tmp_img = preprocessing_img(x)\n",
    "#     testX_pre.append(tmp_img)\n",
    "#     testY_pre.append(y)\n",
    "\n",
    "# print(trainX.shape)\n",
    "# trainX = np.vstack((testX, np.array(trainX_pre)))\n",
    "# print(trainX.shape)\n",
    "# print(trainY.shape)\n",
    "# trainY = np.vstack((testY, np.array(trainY_pre)))\n",
    "# print(trainY.shape)\n",
    "\n",
    "# print(testX.shape)\n",
    "# testX = np.vstack((testX, np.array(testX_pre)))\n",
    "# print(testX.shape)\n",
    "# print(testY.shape)\n",
    "# testY = np.vstack((testY, np.array(testY_pre)))\n",
    "# print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(64, 64, 3))\n",
    "model = keras.applications.Xception(include_top=False, \n",
    "                                    weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None,\n",
    "                                    classes=800)\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "predictions = Dense(800, activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:66]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[66:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block8_sepconv1_act'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[66].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 31, 31, 32)   864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 31, 31, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 31, 31, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 29, 29, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 29, 29, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 29, 29, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 29, 29, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 29, 29, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 29, 29, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 29, 29, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 29, 29, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 15, 15, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 15, 15, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 15, 15, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 15, 15, 128)  0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 15, 15, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 15, 15, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 15, 15, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 15, 15, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 15, 15, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 256)    32768       add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 8, 8, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 8, 8, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 8, 8, 256)    0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 8, 8, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 8, 8, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 728)    186368      add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 4, 4, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 728)    2912        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 4, 4, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 4, 4, 728)    0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 4, 4, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 4, 4, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 4, 4, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 4, 4, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 4, 4, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 4, 4, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 4, 4, 728)    0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 4, 4, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 4, 4, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 4, 4, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 4, 4, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 4, 4, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 4, 4, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 4, 4, 728)    0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 4, 4, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 4, 4, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 4, 4, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 4, 4, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 4, 4, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 4, 4, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 4, 4, 728)    0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 4, 4, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 4, 4, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 4, 4, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 4, 4, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 4, 4, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 4, 4, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 4, 4, 728)    0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 4, 4, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 4, 4, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 4, 4, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 4, 4, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 4, 4, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 4, 4, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 4, 4, 728)    0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 4, 4, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 4, 4, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 4, 4, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 4, 4, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 4, 4, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 4, 4, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 4, 4, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 4, 4, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 4, 4, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 4, 4, 728)    0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 4, 4, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 4, 4, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 4, 4, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 4, 4, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 4, 4, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 4, 4, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 4, 4, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 4, 4, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 4, 4, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 4, 4, 728)    0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 4, 4, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 4, 4, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 4, 4, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 4, 4, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 4, 4, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 4, 4, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 4, 4, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 4, 4, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 4, 4, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 4, 4, 728)    0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 4, 4, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 4, 4, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 4, 4, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 4, 4, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 4, 4, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 1024)   745472      add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 2, 2, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 2, 1024)   4096        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 2, 2, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 2, 2, 1536)   1582080     add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 2, 2, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 2, 2, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 2, 2, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 2, 2, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 2, 2, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8192)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         8389632     flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1024)         4096        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 800)          820000      batch_normalization_33[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,075,208\n",
      "Trainable params: 24,069,944\n",
      "Non-trainable params: 6,005,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.001) \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1498/1498 - 63s - loss: 6.2648 - accuracy: 0.0171 - val_loss: 5.4186 - val_accuracy: 0.0392 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1498/1498 - 63s - loss: 4.2624 - accuracy: 0.1235 - val_loss: 3.8140 - val_accuracy: 0.1763 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1498/1498 - 64s - loss: 3.0933 - accuracy: 0.2834 - val_loss: 3.0437 - val_accuracy: 0.3036 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1498/1498 - 64s - loss: 2.3669 - accuracy: 0.4144 - val_loss: 2.5177 - val_accuracy: 0.3980 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1498/1498 - 64s - loss: 1.8513 - accuracy: 0.5215 - val_loss: 2.3458 - val_accuracy: 0.4513 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1498/1498 - 64s - loss: 1.4758 - accuracy: 0.6051 - val_loss: 2.2139 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1498/1498 - 64s - loss: 1.1560 - accuracy: 0.6771 - val_loss: 2.2985 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1498/1498 - 64s - loss: 0.8948 - accuracy: 0.7436 - val_loss: 2.1825 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1498/1498 - 64s - loss: 0.7004 - accuracy: 0.7921 - val_loss: 2.2396 - val_accuracy: 0.5296 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1498/1498 - 64s - loss: 0.5490 - accuracy: 0.8324 - val_loss: 2.3981 - val_accuracy: 0.5274 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1498/1498 - 65s - loss: 0.4362 - accuracy: 0.8647 - val_loss: 2.3966 - val_accuracy: 0.5439 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1498/1498 - 65s - loss: 0.3973 - accuracy: 0.8747 - val_loss: 2.4596 - val_accuracy: 0.5464 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1498/1498 - 65s - loss: 0.3247 - accuracy: 0.8959 - val_loss: 2.7573 - val_accuracy: 0.5215 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1498/1498 - 65s - loss: 0.2816 - accuracy: 0.9099 - val_loss: 2.6370 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1498/1498 - 65s - loss: 0.2637 - accuracy: 0.9155 - val_loss: 2.7328 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1498/1498 - 65s - loss: 0.1045 - accuracy: 0.9671 - val_loss: 2.1220 - val_accuracy: 0.6205 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1498/1498 - 65s - loss: 0.0447 - accuracy: 0.9878 - val_loss: 2.0932 - val_accuracy: 0.6297 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1498/1498 - 65s - loss: 0.0283 - accuracy: 0.9939 - val_loss: 2.0873 - val_accuracy: 0.6304 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1498/1498 - 65s - loss: 0.0215 - accuracy: 0.9956 - val_loss: 2.0830 - val_accuracy: 0.6347 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1498/1498 - 65s - loss: 0.0163 - accuracy: 0.9969 - val_loss: 2.0886 - val_accuracy: 0.6370 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1498/1498 - 65s - loss: 0.0131 - accuracy: 0.9979 - val_loss: 2.1025 - val_accuracy: 0.6409 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1498/1498 - 65s - loss: 0.0112 - accuracy: 0.9982 - val_loss: 2.0985 - val_accuracy: 0.6430 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1498/1498 - 65s - loss: 0.0102 - accuracy: 0.9983 - val_loss: 2.1154 - val_accuracy: 0.6439 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1498/1498 - 65s - loss: 0.0084 - accuracy: 0.9988 - val_loss: 2.1417 - val_accuracy: 0.6430 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1498/1498 - 65s - loss: 0.0066 - accuracy: 0.9992 - val_loss: 2.1364 - val_accuracy: 0.6467 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1498/1498 - 65s - loss: 0.0065 - accuracy: 0.9991 - val_loss: 2.1689 - val_accuracy: 0.6422 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1498/1498 - 65s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 2.1461 - val_accuracy: 0.6439 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "1498/1498 - 65s - loss: 0.0046 - accuracy: 0.9996 - val_loss: 2.1399 - val_accuracy: 0.6442 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "1498/1498 - 65s - loss: 0.0041 - accuracy: 0.9996 - val_loss: 2.1378 - val_accuracy: 0.6459 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f4b24f088>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=50, verbose=2,\n",
    "          validation_data=(testX, testY), callbacks=callbacks ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1498/1498 - 59s - loss: 6.7332 - accuracy: 0.0086 - val_loss: 5.7409 - val_accuracy: 0.0172 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1498/1498 - 58s - loss: 5.2370 - accuracy: 0.0428 - val_loss: 4.6122 - val_accuracy: 0.0803 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1498/1498 - 58s - loss: 4.1020 - accuracy: 0.1320 - val_loss: 4.1929 - val_accuracy: 0.1374 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1498/1498 - 58s - loss: 3.2775 - accuracy: 0.2445 - val_loss: 3.2044 - val_accuracy: 0.2746 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1498/1498 - 58s - loss: 2.6611 - accuracy: 0.3518 - val_loss: 2.8965 - val_accuracy: 0.3331 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1498/1498 - 58s - loss: 2.1966 - accuracy: 0.4414 - val_loss: 2.7709 - val_accuracy: 0.3801 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1498/1498 - 58s - loss: 1.8129 - accuracy: 0.5200 - val_loss: 2.5793 - val_accuracy: 0.4132 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1498/1498 - 59s - loss: 1.4913 - accuracy: 0.5936 - val_loss: 2.5880 - val_accuracy: 0.4237 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1498/1498 - 59s - loss: 1.2218 - accuracy: 0.6540 - val_loss: 2.4515 - val_accuracy: 0.4592 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1498/1498 - 59s - loss: 0.9797 - accuracy: 0.7141 - val_loss: 2.4826 - val_accuracy: 0.4631 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1498/1498 - 59s - loss: 0.8055 - accuracy: 0.7575 - val_loss: 2.6048 - val_accuracy: 0.4726 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1498/1498 - 59s - loss: 0.6511 - accuracy: 0.7985 - val_loss: 2.7102 - val_accuracy: 0.4716 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1498/1498 - 59s - loss: 0.5606 - accuracy: 0.8259 - val_loss: 2.8107 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1498/1498 - 59s - loss: 0.4841 - accuracy: 0.8478 - val_loss: 2.9791 - val_accuracy: 0.4709 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1498/1498 - 59s - loss: 0.4180 - accuracy: 0.8674 - val_loss: 3.0361 - val_accuracy: 0.4720 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1498/1498 - 59s - loss: 0.3862 - accuracy: 0.8757 - val_loss: 3.1224 - val_accuracy: 0.4792 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1498/1498 - 59s - loss: 0.1539 - accuracy: 0.9527 - val_loss: 2.4915 - val_accuracy: 0.5473 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1498/1498 - 59s - loss: 0.0768 - accuracy: 0.9795 - val_loss: 2.5050 - val_accuracy: 0.5548 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1498/1498 - 59s - loss: 0.0534 - accuracy: 0.9867 - val_loss: 2.5317 - val_accuracy: 0.5592 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f13a3f648>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=50, verbose=2,\n",
    "          validation_data=(testX, testY), callbacks=callbacks ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2996/2996 - 313s - loss: 6.7389 - accuracy: 0.0064 - val_loss: 6.5073 - val_accuracy: 0.0121 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2996/2996 - 316s - loss: 5.3863 - accuracy: 0.0345 - val_loss: 5.0849 - val_accuracy: 0.0510 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2996/2996 - 317s - loss: 4.6345 - accuracy: 0.0815 - val_loss: 4.8776 - val_accuracy: 0.1039 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2996/2996 - 317s - loss: 4.0244 - accuracy: 0.1487 - val_loss: 3.9419 - val_accuracy: 0.1742 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2996/2996 - 319s - loss: 3.4902 - accuracy: 0.2227 - val_loss: 3.7727 - val_accuracy: 0.2083 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2996/2996 - 319s - loss: 3.0054 - accuracy: 0.3009 - val_loss: 3.4232 - val_accuracy: 0.2775 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2996/2996 - 319s - loss: 2.5954 - accuracy: 0.3750 - val_loss: 3.1429 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2996/2996 - 319s - loss: 2.2621 - accuracy: 0.4377 - val_loss: 3.1681 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2996/2996 - 319s - loss: 1.9781 - accuracy: 0.4936 - val_loss: 2.9232 - val_accuracy: 0.3752 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2996/2996 - 319s - loss: 1.7561 - accuracy: 0.5415 - val_loss: 2.9077 - val_accuracy: 0.4089 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2996/2996 - 319s - loss: 1.5126 - accuracy: 0.5905 - val_loss: 2.7699 - val_accuracy: 0.4110 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2996/2996 - 319s - loss: 1.3094 - accuracy: 0.6402 - val_loss: 2.7406 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2996/2996 - 320s - loss: 1.1441 - accuracy: 0.6786 - val_loss: 2.7874 - val_accuracy: 0.4452 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2996/2996 - 319s - loss: 0.9930 - accuracy: 0.7151 - val_loss: 3.0401 - val_accuracy: 0.4422 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2996/2996 - 320s - loss: 0.8652 - accuracy: 0.7455 - val_loss: 2.9888 - val_accuracy: 0.4486 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2996/2996 - 319s - loss: 0.7620 - accuracy: 0.7729 - val_loss: 4.2841 - val_accuracy: 0.4385 - lr: 0.0010\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-73658635161f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(trainX, trainY, batch_size=32, epochs=50, verbose=2,\n\u001b[1;32m----> 2\u001b[1;33m           validation_data=(testX, testY), callbacks=callbacks ) \n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=50, verbose=2,\n",
    "          validation_data=(testX, testY), callbacks=callbacks ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=10, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=10, validation_data=(testX, testY), workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=10, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=50, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(include_top=True,input_tensor=None, input_shape=(128, 128, 1),\n",
    "          pooling='max',classes=800):\n",
    " \n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "  \n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(1000, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(trainX, trainY, batch_size=32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-gpu",
   "language": "python",
   "name": "cv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
