{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Flatten, Dense, Input, \n",
    "                                     Dropout, BatchNormalization,\n",
    "                                     Conv2D, MaxPooling2D, \n",
    "                                     GlobalMaxPooling2D, GlobalAveragePooling2D,)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_show(img, name='image'):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(img):\n",
    "    # 先padding再裁切\n",
    "    \n",
    "    out_w = 128\n",
    "    out_h = 128\n",
    "    top_size = int((128 - img.shape[0]) / 2)\n",
    "    bottom_size = int((128 - img.shape[0]) / 2)\n",
    "    dif_1 = 128 - (top_size + bottom_size + img.shape[0])\n",
    "    top_size += dif_1\n",
    "    left_size = int((128 - img.shape[1]) / 2)\n",
    "    right_size = int((128 - img.shape[1]) / 2)\n",
    "    dif_2 = 128 - (left_size + right_size + img.shape[1])\n",
    "    left_size += dif_2    \n",
    "    padding_v = tuple(img[-1, -1, :])\n",
    "    if img.shape[1] <= 128:\n",
    "        padding = cv2.copyMakeBorder(img, \n",
    "                                  top_size, bottom_size, left_size, right_size, \n",
    "                                  borderType=cv2.BORDER_CONSTANT, \n",
    "                                  value=(int(padding_v[0]), int(padding_v[1]), int(padding_v[2])))\n",
    "    else:\n",
    "        padding = cv2.copyMakeBorder(img, \n",
    "                          top_size, bottom_size, 0, 0, \n",
    "                          borderType=cv2.BORDER_CONSTANT, \n",
    "                          value=(int(padding_v[0]), int(padding_v[1]), int(padding_v[2])))\n",
    "        padding = cv2.resize(padding, (128, 128))\n",
    "\n",
    "\n",
    "    # 灰階 二值化\n",
    "    gray = cv2.cvtColor(padding, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_OTSU)\n",
    "    # 黑白轉換\n",
    "    thresh = 255 - thresh\n",
    "    # 閉操作\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    # 腐蝕 & 膨脹\n",
    "    closed = cv2.erode(closed, None, iterations=1)\n",
    "    closed = cv2.dilate(closed, None, iterations=1)\n",
    "    # 輪廓檢測\n",
    "    contours, hierarchy = cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) == 0:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "        thresh = 255 - thresh\n",
    "\n",
    "    else:    \n",
    "        # 取出最大的\n",
    "        c = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "        if (cv2.contourArea(c) > 1000) and (len(contours) > 1):\n",
    "            # 閉操作\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "            closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            # 腐蝕 & 膨脹\n",
    "            closed = cv2.erode(closed, None, iterations=1)\n",
    "            closed = cv2.dilate(closed, None, iterations=1)\n",
    "            # 輪廓檢測\n",
    "            contours, hierarchy = cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            c = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "            \n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = np.int0(cv2.boxPoints(rect))\n",
    "        # 裁切\n",
    "        Xs = [i[0] for i in box]\n",
    "        Ys = [i[1] for i in box]\n",
    "        x1 = min(Xs)\n",
    "        x2 = max(Xs)\n",
    "        y1 = min(Ys)\n",
    "        y2 = max(Ys)\n",
    "        hight = y2 - y1\n",
    "        width = x2 - x1\n",
    "#         padding = padding[y1: y1+hight, x1: x1+width]\n",
    "        thresh = thresh[y1: y1+hight, x1: x1+width]\n",
    "        \n",
    "    # reshape\n",
    "    img2 = cv2.resize(thresh, (64, 64))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "     \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    fold_list = os.listdir(train_dir)\n",
    "    trainX_list = []\n",
    "    trainY_list = []\n",
    "    testX_list = []\n",
    "    testY_list = []\n",
    "\n",
    "    for f in fold_list:\n",
    "        label = int(f)\n",
    "        img_list = os.listdir(f'{train_dir}{f}')\n",
    "        tmp_datasetX = []\n",
    "        tmp_datasetY = []\n",
    "        for img_p in img_list:\n",
    "            try:\n",
    "                img = cv2.imread(f'{train_dir}{f}/{img_p}')\n",
    "                img = preprocessing_img(img)\n",
    "                label = int(f)\n",
    "                tmp_datasetX.append(img)\n",
    "                tmp_datasetY.append(label)\n",
    "            except Exception as e:\n",
    "                print(f, img_p)\n",
    "                print(e)\n",
    "        \n",
    "        trainX, testX, trainY, testY = train_test_split(tmp_datasetX, tmp_datasetY, test_size=0.2, random_state=42)\n",
    "        trainX_list.extend(trainX)\n",
    "        trainY_list.extend(trainY)\n",
    "        testX_list.extend(testX)\n",
    "        testY_list.extend(testY)\n",
    "    trainX_ary = np.array(trainX_list)\n",
    "    trainY_ary = np.array(trainY_list)\n",
    "    testX_ary = np.array(testX_list)\n",
    "    testY_ary = np.array(testY_list)\n",
    "    print(f'trainX: {trainX_ary.shape}')\n",
    "    print(f'trainY: {trainY_ary.shape}')\n",
    "    print(f'testX: {testX_ary.shape}')\n",
    "    print(f'testY: {testY_ary.shape}')\n",
    "        \n",
    "    return trainX_ary, testX_ary, trainY_ary, testY_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'./data-clean/'\n",
    "df = pd.read_csv('word_idx_df.csv', converters={'idx':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 8844.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "595 58299.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "633 15394.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "691 22184.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "691 42847.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "741 10297.jpg\n",
      "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "trainX: (47925, 64, 64, 3)\n",
      "trainY: (47925,)\n",
      "testX: (12390, 64, 64, 3)\n",
      "testY: (12390,)\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = load_data(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, num_classes=800)\n",
    "testY = keras.utils.to_categorical(testY, num_classes=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47925, 64, 64, 3)\n",
      "(12390, 64, 64, 3)\n",
      "(47925, 800)\n",
      "(12390, 800)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5842"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(64, 64, 3))\n",
    "# input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "model = keras.applications.Xception(include_top=False, \n",
    "                                    weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None,\n",
    "                                    classes=800)\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "predictions = Dense(800, activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:76]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[76:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block9_sepconv1_act'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[76].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.001) \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1498/1498 - 59s - loss: 6.7132 - accuracy: 0.0075 - val_loss: 6.3427 - val_accuracy: 0.0186 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1498/1498 - 59s - loss: 5.2128 - accuracy: 0.0586 - val_loss: 4.7741 - val_accuracy: 0.1049 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1498/1498 - 59s - loss: 4.2331 - accuracy: 0.1593 - val_loss: 4.1593 - val_accuracy: 0.1808 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1498/1498 - 59s - loss: 3.4994 - accuracy: 0.2674 - val_loss: 3.5831 - val_accuracy: 0.2786 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1498/1498 - 60s - loss: 2.9703 - accuracy: 0.3552 - val_loss: 3.3191 - val_accuracy: 0.3254 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1498/1498 - 60s - loss: 2.5423 - accuracy: 0.4330 - val_loss: 3.1808 - val_accuracy: 0.3491 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1498/1498 - 60s - loss: 2.1702 - accuracy: 0.5026 - val_loss: 3.3704 - val_accuracy: 0.3484 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1498/1498 - 60s - loss: 1.8364 - accuracy: 0.5660 - val_loss: 3.1680 - val_accuracy: 0.3945 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1498/1498 - 60s - loss: 1.5517 - accuracy: 0.6271 - val_loss: 3.2362 - val_accuracy: 0.3981 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1498/1498 - 60s - loss: 1.3143 - accuracy: 0.6753 - val_loss: 3.2404 - val_accuracy: 0.3993 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1498/1498 - 60s - loss: 1.0958 - accuracy: 0.7235 - val_loss: 3.5628 - val_accuracy: 0.3847 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1498/1498 - 60s - loss: 0.9292 - accuracy: 0.7587 - val_loss: 3.6932 - val_accuracy: 0.3897 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1498/1498 - 60s - loss: 0.7933 - accuracy: 0.7889 - val_loss: 3.7453 - val_accuracy: 0.4035 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1498/1498 - 60s - loss: 0.6854 - accuracy: 0.8137 - val_loss: 4.1195 - val_accuracy: 0.3812 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1498/1498 - 60s - loss: 0.5920 - accuracy: 0.8365 - val_loss: 4.2696 - val_accuracy: 0.3926 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1498/1498 - 60s - loss: 0.2752 - accuracy: 0.9248 - val_loss: 3.6771 - val_accuracy: 0.4470 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1498/1498 - 60s - loss: 0.1668 - accuracy: 0.9590 - val_loss: 3.7180 - val_accuracy: 0.4503 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1498/1498 - 60s - loss: 0.1279 - accuracy: 0.9706 - val_loss: 3.7826 - val_accuracy: 0.4530 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x185a0948448>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=32, epochs=50, verbose=2,\n",
    "          validation_data=(testX, testY), callbacks=callbacks ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-gpu",
   "language": "python",
   "name": "cv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
